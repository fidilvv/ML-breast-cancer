# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# 1. Loading and Preprocessing

# Load the breast cancer dataset
data = load_breast_cancer()
X = data.data
y = data.target

# Convert to DataFrame for easier analysis
df = pd.DataFrame(X, columns=data.feature_names)
df['target'] = y

# Check for missing values
print("Missing values in each column:")
print(df.isnull().sum())

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# 2. Classification Algorithm Implementation

# Initialize the classifiers
models = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC(),
    "k-NN": KNeighborsClassifier()
}

# Function to evaluate models
def evaluate_model(model):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)

# 3. Model Comparison

results = {name: evaluate_model(model) for name, model in models.items()}

# Print the results
print("\nModel Comparison Results:")
for name, score in results.items():
    print(f"{name}: {score:.4f}")

# Identify the best and worst performing models
best_model = max(results, key=results.get)
worst_model = min(results, key=results.get)

print(f"\nBest Performing Model: {best_model} with accuracy: {results[best_model]:.4f}")
print(f"Worst Performing Model: {worst_model} with accuracy: {results[worst_model]:.4f}")
